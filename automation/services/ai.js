const { OpenAI } = require('openai');
const tf = require('@tensorflow/tfjs-node');

class AIService {
  constructor(config) {
    this.config = config;
    this.openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY
    });
    this.models = new Map();
  }

  async startAnomalyDetection() {
    console.log('๐ Starting anomaly detection system...');
    
    if (this.config.anomaly_detection.enabled) {
      await this.initializeAnomalyDetectionModel();
    }
  }

  async initializeAnomalyDetectionModel() {
    // ุฅูุดุงุก ูููุฐุฌ ูููุดู ุนู ุงูุฃููุงุท ุบูุฑ ุงูุทุจูุนูุฉ
    const model = tf.sequential();
    
    model.add(tf.layers.dense({
      units: 32,
      inputShape: [10],
      activation: 'relu'
    }));
    
    model.add(tf.layers.dense({
      units: 16,
      activation: 'relu'
    }));
    
    model.add(tf.layers.dense({
      units: 8,
      activation: 'relu'
    }));
    
    model.add(tf.layers.dense({
      units: 1,
      activation: 'sigmoid'
    }));
    
    model.compile({
      optimizer: tf.train.adam(this.config.anomaly_detection.learning_rate),
      loss: 'binaryCrossentropy',
      metrics: ['accuracy']
    });
    
    this.models.set('anomaly_detection', model);
  }

  async enablePredictiveMaintenance() {
    console.log('๐ฎ Enabling predictive maintenance...');
    
    if (this.config.predictive_maintenance.enabled) {
      await this.initializePredictiveModel();
    }
  }

  async initializePredictiveModel() {
    // ุฅูุดุงุก ูููุฐุฌ ููุชูุจุค ุจุงูุตูุงูุฉ
    const model = tf.sequential();
    
    model.add(tf.layers.lstm({
      units: 64,
      inputShape: [30, 5], // 30 ููู ูู ุงูุจูุงูุงุชุ 5 ููุงููุณ
      returnSequences: true
    }));
    
    model.add(tf.layers.dropout(0.2));
    
    model.add(tf.layers.lstm({
      units: 32,
      returnSequences: false
    }));
    
    model.add(tf.layers.dense({
      units: this.config.predictive_maintenance.forecast_days
    }));
    
    model.compile({
      optimizer: 'adam',
      loss: 'meanSquaredError'
    });
    
    this.models.set('predictive_maintenance', model);
  }

  async optimizeResources() {
    console.log('โก Starting resource optimization...');
    
    if (this.config.resource_optimization.enabled) {
      await this.initializeOptimizationModel();
    }
  }

  async initializeOptimizationModel() {
    // ุฅูุดุงุก ูููุฐุฌ ูุชุญุณูู ุงูููุงุฑุฏ
    const model = tf.sequential();
    
    model.add(tf.layers.dense({
      units: 64,
      inputShape: [20],
      activation: 'relu'
    }));
    
    model.add(tf.layers.dense({
      units: 32,
      activation: 'relu'
    }));
    
    model.add(tf.layers.dense({
      units: 16,
      activation: 'relu'
    }));
    
    model.add(tf.layers.dense({
      units: 8,
      activation: 'softmax'
    }));
    
    model.compile({
      optimizer: 'adam',
      loss: 'categoricalCrossentropy',
      metrics: ['accuracy']
    });
    
    this.models.set('resource_optimization', model);
  }

  async analyzeMetrics(metrics) {
    console.log('๐ Analyzing metrics...');
    
    try {
      // ุชุญููู ุงูููุงููุณ ุจุงุณุชุฎุฏุงู ููุฌ ููููุณ ุชูุฑูุงูุฏุฒ
      const systemPrompt = {
        role: 'system',
        content: `ุฃูุช ูุญูู ุฃุฏุงุก ูุชุฎุตุต ูู ููุตุงุช ุงูุจุซ ุงููุจุงุดุฑ. ุงุณุชุฎุฏู ููุฌ ููููุณ ุชูุฑูุงูุฏุฒ ูู:
- ุชุญููู ุฏููู ููุฃุฏุงุก
- ุชุญุฏูุฏ ููุงุท ุงูุถุนู
- ุงูุชุฑุงุญ ุชุญุณููุงุช ุนูููุฉ
- ุงูุชุฑููุฒ ุนูู ุงูููุงุกุฉ
`
      };

      const analysis = await this.openai.chat.completions.create({
        model: 'gpt-4',
        messages: [
          systemPrompt,
          {
            role: 'system',
            content: 'You are an AI system analyst specializing in performance metrics analysis.'
          },
          {
            role: 'user',
            content: `Analyze these metrics and provide insights: ${JSON.stringify(metrics)}`
          }
        ]
      });
      
      return {
        insights: analysis.choices[0].message.content,
        anomalies: await this.detectAnomalies(metrics),
        trends: await this.analyzeTrends(metrics)
      };
    } catch (error) {
      console.error('Error analyzing metrics:', error);
      return null;
    }
  }

  async detectAnomalies(data) {
    const model = this.models.get('anomaly_detection');
    if (!model) return [];
    
    const tensor = this.preprocessData(data);
    const predictions = model.predict(tensor);
    
    return this.postprocessAnomalies(predictions);
  }

  async analyzeTrends(data) {
    try {
      // ุชุญููู ุงูุงุชุฌุงูุงุช ุจุงุณุชุฎุฏุงู ููุฌ ููููุณ ุชูุฑูุงูุฏุฒ
      const systemPrompt = {
        role: 'system',
        content: `ุฃูุช ูุญูู ุงุชุฌุงูุงุช ูุชุฎุตุต ูู ููุตุงุช ุงูุจุซ ุงููุจุงุดุฑ. ุงุณุชุฎุฏู ููุฌ ููููุณ ุชูุฑูุงูุฏุฒ ูู:
- ุชุญุฏูุฏ ุงูุงุชุฌุงูุงุช ุงููุคุซุฑุฉ
- ุชุญููู ุณููู ุงููุณุชุฎุฏู
- ุชููุน ุงูุชุบููุฑุงุช ุงููุณุชูุจููุฉ
- ุงูุชุฑุงุญ ุงูุชุญุณููุงุช ุงูุงุณุชุจุงููุฉ
`
      };

      const trends = await this.openai.chat.completions.create({
        model: 'gpt-4',
        messages: [
          systemPrompt,
          {
            role: 'system',
            content: 'You are a trend analysis expert. Identify patterns and trends in the data.'
          },
          {
            role: 'user',
            content: `Analyze these trends: ${JSON.stringify(data)}`
          }
        ]
      });
      
      return trends.choices[0].message.content;
    } catch (error) {
      console.error('Error analyzing trends:', error);
      return null;
    }
  }

  async generateRecommendations(insights) {
    try {
      // ุชุญุณูู ุงูุชูุตูุงุช ุจุงุณุชุฎุฏุงู ููุฌ ููููุณ ุชูุฑูุงูุฏุฒ
      const systemPrompt = {
        role: 'system',
        content: `ุฃูุช ูุณุชุดุงุฑ ุฎุจูุฑ ูู ุชุญุณูู ููุตุงุช ุงูุจุซ ุงููุจุงุดุฑ. ุงุณุชุฎุฏู ููุฌ ููููุณ ุชูุฑูุงูุฏุฒ ูู:
- ุงูุชุฑููุฒ ุนูู ุงูุฃุฏุงุก ูุงูููุซูููุฉ
- ุชุจุณูุท ุงูุชุตููู ูุงูุญููู
- ุงูุญูุงุธ ุนูู ุฌูุฏุฉ ุงูููุฏ ุงูุนุงููุฉ
- ุงูุชุฑููุฒ ุนูู ุชุฌุฑุจุฉ ุงููุณุชุฎุฏู
`
      };

      const recommendations = await this.openai.chat.completions.create({
        model: 'gpt-4',
        messages: [
          systemPrompt,
          {
            role: 'system',
            content: 'You are an AI system optimizer. Provide actionable recommendations based on insights.'
          },
          {
            role: 'user',
            content: `Generate recommendations based on these insights: ${JSON.stringify(insights)}`
          }
        ]
      });
      
      return recommendations.choices[0].message.content;
    } catch (error) {
      console.error('Error generating recommendations:', error);
      return null;
    }
  }

  async analyzeAlert(alert) {
    try {
      const analysis = await this.openai.chat.completions.create({
        model: 'gpt-4',
        messages: [
          {
            role: 'system',
            content: 'You are an AI alert analyzer. Analyze the alert and suggest resolution steps.'
          },
          {
            role: 'user',
            content: `Analyze this alert and provide resolution steps: ${JSON.stringify(alert)}`
          }
        ]
      });
      
      return {
        description: analysis.choices[0].message.content,
        canAutoResolve: this.canAutoResolve(alert),
        resolution: this.generateResolutionSteps(alert)
      };
    } catch (error) {
      console.error('Error analyzing alert:', error);
      return null;
    }
  }

  canAutoResolve(alert) {
    // ุชุญุฏูุฏ ูุง ุฅุฐุง ูุงู ูููู ุญู ุงูุชูุจูู ุชููุงุฆูุงู
    const autoResolvableTypes = ['high_cpu_usage', 'high_memory_usage', 'cache_full'];
    return autoResolvableTypes.includes(alert.type);
  }

  generateResolutionSteps(alert) {
    // ุชูููุฏ ุฎุทูุงุช ุงูุญู ุจูุงุกู ุนูู ููุน ุงูุชูุจูู
    switch (alert.type) {
      case 'high_cpu_usage':
        return {
          type: 'scale',
          action: 'increase_workers'
        };
      case 'high_memory_usage':
        return {
          type: 'optimize',
          action: 'clear_cache'
        };
      case 'cache_full':
        return {
          type: 'optimize',
          action: 'prune_cache'
        };
      default:
        return null;
    }
  }

  async performDeepAnalysis(data) {
    return {
      trends: await this.analyzeTrends(data),
      anomalies: await this.detectAnomalies(data),
      predictions: await this.generatePredictions(data),
      optimizations: await this.suggestOptimizations(data)
    };
  }

  async generateStrategicPlan(analysis) {
    try {
      const plan = await this.openai.chat.completions.create({
        model: 'gpt-4',
        messages: [
          {
            role: 'system',
            content: 'You are an AI strategic planner. Generate a comprehensive improvement plan.'
          },
          {
            role: 'user',
            content: `Create a strategic plan based on this analysis: ${JSON.stringify(analysis)}`
          }
        ]
      });
      
      return plan.choices[0].message.content;
    } catch (error) {
      console.error('Error generating strategic plan:', error);
      return null;
    }
  }

  preprocessData(data) {
    // ุชุญููู ุงูุจูุงูุงุช ุฅูู ุชูุณูู ููุงุณุจ ูููููุฐุฌ
    return tf.tensor2d([Object.values(data)]);
  }

  postprocessAnomalies(predictions) {
    // ูุนุงูุฌุฉ ูุชุงุฆุฌ ุงููุดู ุนู ุงูุฃููุงุท ุบูุฑ ุงูุทุจูุนูุฉ
    return Array.from(predictions.dataSync())
      .map((prob, index) => ({
        index,
        probability: prob,
        isAnomaly: prob > 0.8
      }));
  }

  async stop() {
    console.log('โน๏ธ Stopping AI service...');
    // ุชูุธูู ุงูููุงุฑุฏ
    this.models.clear();
    console.log('โ AI service stopped');
  }
}

module.exports = AIService;